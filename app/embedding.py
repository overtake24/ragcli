# app/embedding.py
"""
DokÃ¼man yÃ¼kleme, parÃ§alama ve vektÃ¶rleÅŸtirme iÅŸlemleri
"""
import os
import sys
import json
import time
from typing import List, Dict, Any, Optional

from app.db import get_db_connection
from sentence_transformers import SentenceTransformer
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import SentenceTransformerEmbeddings

from app.config import EMBEDDING_MODEL, DEFAULT_CHUNK_SIZE, DEFAULT_CHUNK_OVERLAP

# Default embedding model
DEFAULT_EMBEDDING_MODEL = EMBEDDING_MODEL
_embedding_model = None


def get_embedding_model(model_name: str = DEFAULT_EMBEDDING_MODEL) -> SentenceTransformer:
    """YÃ¼klÃ¼ embedding modelini dÃ¶ndÃ¼r veya yÃ¼kle"""
    global _embedding_model

    # Model adÄ± None ise varsayÄ±lan deÄŸeri kullan
    if model_name is None:
        model_name = DEFAULT_EMBEDDING_MODEL
        print(f"UYARI - Model adÄ± None, varsayÄ±lan model kullanÄ±lÄ±yor: {DEFAULT_EMBEDDING_MODEL}")

    # EÄŸer model yÃ¼klÃ¼yse ve istenen model aynÄ±ysa, mevcut modeli kullan
    if _embedding_model is not None and _embedding_model.get("name") == model_name:
        return _embedding_model.get("model")

    # Modeli yÃ¼kle
    try:
        print(f"INFO - Embedding modeli yÃ¼kleniyor: {model_name}")
        model = SentenceTransformer(model_name)
        _embedding_model = {
            "name": model_name,
            "model": model
        }
        return model
    except Exception as e:
        print(f"ERROR - Embedding modeli yÃ¼klenirken hata: {e}")
        print(f"Model: {model_name}")
        raise


def get_embeddings(model_name=None):
    """Embedding modelini dÃ¶ndÃ¼rÃ¼r"""
    from app.config import EMBEDDING_MODEL
    if model_name is None:
        model_name = EMBEDDING_MODEL
    print(f"INFO - Embedding modeli kullanÄ±lÄ±yor: {model_name}")
    return SentenceTransformerEmbeddings(model_name=model_name)


def generate_embeddings(texts: List[str], model_name: str = DEFAULT_EMBEDDING_MODEL) -> List[List[float]]:
    """Metinler iÃ§in embedding vektÃ¶rleri oluÅŸtur"""
    # Model adÄ± None ise varsayÄ±lan deÄŸeri kullan
    if model_name is None:
        model_name = DEFAULT_EMBEDDING_MODEL
        print(f"UYARI - Model adÄ± None, varsayÄ±lan model kullanÄ±lÄ±yor: {DEFAULT_EMBEDDING_MODEL}")

    model = get_embedding_model(model_name)
    return model.encode(texts).tolist()


def chunk_document(content: str, title: str = "Untitled",
                   chunk_size: int = DEFAULT_CHUNK_SIZE,
                   chunk_overlap: int = DEFAULT_CHUNK_OVERLAP) -> List[Dict[str, Any]]:
    """DokÃ¼manÄ± parÃ§alara bÃ¶l"""
    # Markdown baÅŸlÄ±klarÄ±nÄ± ve listelerini koruyarak bÃ¶l
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        is_separator_regex=False,
    )

    chunks = text_splitter.split_text(content)
    print(f"INFO - Belge {len(chunks)} parÃ§aya bÃ¶lÃ¼ndÃ¼. Belge boyutu: {len(content)} karakter")

    # Her bir parÃ§ayÄ± hazÄ±rla
    document_chunks = []
    for i, chunk in enumerate(chunks):
        document_chunks.append({
            "title": title,
            "content": chunk,
            "chunk_index": i,
            "total_chunks": len(chunks)
        })

    return document_chunks


def save_chunks_to_db(document_id: str, chunks: List[Dict[str, Any]],
                      model_name: str = DEFAULT_EMBEDDING_MODEL) -> int:
    """Belge parÃ§alarÄ±nÄ± veritabanÄ±na kaydet"""
    if not chunks:
        print("UYARI - Kaydedilecek belge parÃ§asÄ± bulunamadÄ±")
        return 0

    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        # TÃ¼m parÃ§alarÄ±n iÃ§erik metinlerini al
        texts = [chunk["content"] for chunk in chunks]

        # VektÃ¶rler oluÅŸtur
        print(f"INFO - {len(texts)} parÃ§a iÃ§in embedding vektÃ¶rleri oluÅŸturuluyor...")
        # Model adÄ± None ise varsayÄ±lan deÄŸeri kullan - Ã¶nemli dÃ¼zeltme
        if model_name is None:
            model_name = DEFAULT_EMBEDDING_MODEL
            print(f"UYARI - Model adÄ± None, varsayÄ±lan model kullanÄ±lÄ±yor: {DEFAULT_EMBEDDING_MODEL}")

        embeddings = generate_embeddings(texts, model_name)

        # Her bir parÃ§ayÄ± veritabanÄ±na kaydet
        for i, chunk in enumerate(chunks):
            cursor.execute("""
            INSERT INTO document_chunks 
                (document_id, title, content, chunk_index, total_chunks, embedding, embedding_model)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            """, (
                document_id,
                chunk["title"],
                chunk["content"],
                chunk["chunk_index"],
                chunk["total_chunks"],
                embeddings[i],
                model_name  # Burada model_name kullanÄ±lÄ±yor
            ))

        conn.commit()
        print(f"INFO - {len(chunks)} belge parÃ§asÄ± veritabanÄ±na kaydedildi")
        return len(chunks)
    except Exception as e:
        conn.rollback()
        print(f"HATA - Veri kaydedilirken hata: {e}")
        raise
    finally:
        cursor.close()
        conn.close()


def extract_title_from_content(content: str) -> str:
    """Ä°Ã§erikten baÅŸlÄ±k Ã§Ä±kar (markdown baÅŸlÄ±klarÄ±na bakarak)"""
    lines = content.strip().split('\n')

    for line in lines:
        line = line.strip()
        # H1 baÅŸlÄ±k kontrolÃ¼ (# ile baÅŸlayan)
        if line.startswith('# '):
            return line[2:].strip()

    # BaÅŸlÄ±k bulunamadÄ±ysa dosya adÄ±nÄ± kullan
    return "Untitled Document"


def load_document(file_path: str, model_name: str = DEFAULT_EMBEDDING_MODEL) -> int:
    """Tek bir dokÃ¼manÄ± yÃ¼kle ve iÅŸle"""
    try:
        # Dosya adÄ±ndan document_id oluÅŸtur
        base_name = os.path.basename(file_path)
        document_id = os.path.splitext(base_name)[0]

        print(f"INFO - Dosya yÃ¼kleniyor: {file_path}")

        # DosyayÄ± oku
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # BaÅŸlÄ±k Ã§Ä±kar
        title = extract_title_from_content(content)
        print(f"INFO - BaÅŸlÄ±k: {title}")

        # DokÃ¼manÄ± parÃ§ala
        chunks = chunk_document(content, title)

        # VeritabanÄ±na kaydet - model adÄ±nÄ± dÃ¼zgÃ¼n bir ÅŸekilde geÃ§ir
        return save_chunks_to_db(document_id, chunks, model_name)
    except Exception as e:
        print(f"HATA - Dosya yÃ¼klenirken hata: {e}")
        print(f"Dosya: {file_path}")
        return 0


def load_documents(path: str, model_name: str = DEFAULT_EMBEDDING_MODEL) -> int:
    """DokÃ¼manlarÄ± yÃ¼kle ve iÅŸle"""
    total_chunks = 0

    if os.path.isfile(path):
        # Tek dosya
        print(f"ğŸ“„ Dosya indeksleniyor: {path}")
        total_chunks = load_document(path, model_name)
    elif os.path.isdir(path):
        # KlasÃ¶rdeki tÃ¼m .txt ve .md dosyalarÄ±nÄ± iÅŸle
        print(f"ğŸ“ KlasÃ¶r indeksleniyor: {path}")
        for root, _, files in os.walk(path):
            for file in files:
                if file.endswith(('.txt', '.md')):
                    file_path = os.path.join(root, file)
                    chunks_count = load_document(file_path, model_name)
                    total_chunks += chunks_count
                    print(f"YÃ¼klenen: {file} ({chunks_count} parÃ§a)")
    else:
        raise ValueError(f"GeÃ§ersiz dosya yolu: {path}")

    if total_chunks > 0:
        print(f"âœ… {total_chunks} belge parÃ§asÄ± baÅŸarÄ±yla indekslendi")
    else:
        print("âŒ Indekslenecek belge bulunamadÄ± veya iÅŸlem sÄ±rasÄ±nda hata oluÅŸtu")

    return total_chunks
