#!/usr/bin/env python3
"""
RAG sorgu tanÄ±lama aracÄ± - baÄŸlam ve LLM yanÄ±t aÅŸamalarÄ±nÄ± inceler
"""
import os
import sys
import json
import numpy as np
from typing import List, Dict, Any, Optional

from app.db import get_db_connection
from app.embedding import get_embedding_model
from app.config import PROMPT_TEMPLATE_FILE, LLM_MODEL
from langchain_community.llms import Ollama


def cosine_similarity(a, b):
    """Ä°ki vektÃ¶r arasÄ±ndaki kosinÃ¼s benzerliÄŸini hesaplar"""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


def debug_query(query: str):
    """RAG sorgu sÃ¼recini adÄ±m adÄ±m inceler"""
    print(f"ðŸ” Sorgu inceleniyor: '{query}'")

    try:
        # 1. Embedding oluÅŸtur
        print("\n1ï¸âƒ£ Embedding modeli yÃ¼kleniyor...")
        model = get_embedding_model()
        query_vector = model.encode(query)
        print(f"   Sorgu vektÃ¶rÃ¼ boyutu: {len(query_vector)}")

        # 2. Benzer belgeleri ara
        print("\n2ï¸âƒ£ VeritabanÄ±nda benzer belgeler aranÄ±yor...")
        conn = get_db_connection()
        cursor = conn.cursor()

        # 2.1 Scandinavia iÃ§eren dokÃ¼manlarÄ± kontrol et
        cursor.execute("SELECT COUNT(*) FROM document_chunks WHERE content ILIKE %s", ('%scandinavia%',))
        scandinavia_count = cursor.fetchone()[0]
        print(f"   'Scandinavia' iÃ§eren belge sayÄ±sÄ±: {scandinavia_count}")

        # 2.2 Manuel benzerlik hesapla
        cursor.execute("SELECT id, document_id, title, content FROM document_chunks")
        documents = cursor.fetchall()
        print(f"   Toplam belge sayÄ±sÄ±: {len(documents)}")

        similarities = []
        for doc_id, document_id, title, content in documents:
            doc_vector = model.encode(content[:1000])  # Ä°lk 1000 karakter yeterli olacaktÄ±r
            sim = cosine_similarity(query_vector, doc_vector)
            similarities.append((doc_id, document_id, title, sim))

        # En benzer 3 belgeyi yazdÄ±r
        top_similar = sorted(similarities, key=lambda x: x[3], reverse=True)[:3]
        print("\n   En benzer belgeler:")
        for doc_id, document_id, title, sim in top_similar:
            print(f"     - {document_id} ({title}): {sim:.4f}")

        # 3. Benzer belgelerden baÄŸlam oluÅŸtur
        print("\n3ï¸âƒ£ BaÄŸlam oluÅŸturuluyor...")
        context_docs = []
        for doc_id, document_id, title, sim in top_similar:
            cursor.execute("SELECT content FROM document_chunks WHERE id = %s", (doc_id,))
            content = cursor.fetchone()[0]
            context_docs.append(content[:300] + "...")  # Ä°lk 300 karakter

        context = "\n\n".join(context_docs)
        print(f"   OluÅŸturulan baÄŸlam (ilk 200 karakter):")
        print(f"   {context[:200]}...")

        # 4. Promptu hazÄ±rla
        print("\n4ï¸âƒ£ Prompt hazÄ±rlanÄ±yor...")
        with open(PROMPT_TEMPLATE_FILE, 'r', encoding='utf-8') as f:
            templates = json.load(f)

        template_name = "default"
        system_content = templates[template_name]["messages"][0]["content"]
        user_content = templates[template_name]["messages"][1]["content"]

        # Prompt'u biÃ§imlendir
        prompt = user_content.replace("{query}", query).replace("{context}", context)
        print(f"   Sistem mesajÄ± (ilk 100 karakter): {system_content[:100]}...")
        print(f"   KullanÄ±cÄ± mesajÄ± (ilk 100 karakter): {prompt[:100]}...")

        # 5. LLM'e gÃ¶nder
        print("\n5ï¸âƒ£ LLM yanÄ±tÄ± alÄ±nÄ±yor...")
        llm = Ollama(model=LLM_MODEL)
        response = llm.invoke(system_content + "\n\n" + prompt)

        print("\nðŸ“ LLM YanÄ±tÄ±:")
        print("=" * 50)
        print(response)

        cursor.close()
        conn.close()

    except Exception as e:
        print(f"\nâŒ Hata: {e}")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        query = sys.argv[1]
    else:
        query = input("Sorgunuzu girin: ")

    debug_query(query)